{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354571b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from dotenv import load_dotenv\n",
    "import assemblyai as aai\n",
    "import os\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "aai.settings.api_key = os.getenv(\"ASSEMBLYAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5808c0",
   "metadata": {},
   "source": [
    "REECORDS CONVERSATION, SAVES TO WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "862f0873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press ENTER to start recording...\n",
      "Recording... Press ENTER again to stop.\n",
      "Saved recording to input_audio.wav\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "\n",
    "fs = 44100  # Sample rate\n",
    "channels = 1\n",
    "\n",
    "print(\"Press ENTER to start recording...\")\n",
    "input()\n",
    "\n",
    "print(\"Recording... Press ENTER again to stop.\")\n",
    "recorded_chunks = []\n",
    "\n",
    "# Callback for non-blocking recording\n",
    "def callback(indata, frames, time, status):\n",
    "    recorded_chunks.append(indata.copy())\n",
    "\n",
    "stream = sd.InputStream(samplerate=fs, channels=channels, callback=callback)\n",
    "with stream:\n",
    "    input()  # Wait until user presses Enter\n",
    "    # Exiting the 'with' block stops the stream\n",
    "\n",
    "# Combine all chunks\n",
    "audio_np = np.concatenate(recorded_chunks, axis=0)\n",
    "write(\"input_audio.wav\", fs, audio_np)\n",
    "\n",
    "print(\"Saved recording to input_audio.wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d4442",
   "metadata": {},
   "source": [
    "WAV TO TXT TRANSCRIPT, END AS SPEAKER A/B..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9549c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote transcript to REALTIME_transcript.txt\n"
     ]
    }
   ],
   "source": [
    "#path to audio file\n",
    "audio_file = \"input_audio.wav\"\n",
    "\n",
    "config = aai.TranscriptionConfig(\n",
    "    speech_model=aai.SpeechModel.universal,\n",
    "    speaker_labels=True \n",
    ")\n",
    "\n",
    "transcript = aai.Transcriber(config=config).transcribe(audio_file)\n",
    "\n",
    "if transcript.status == \"error\":\n",
    "    raise RuntimeError(f\"Transcription failed: {transcript.error}\")\n",
    "\n",
    "basename = os.path.splitext(os.path.basename(audio_file))[0]\n",
    "out_path = f\"REALTIME_transcript.txt\"\n",
    "\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for u in transcript.utterances:\n",
    "        start = u.start / 1000\n",
    "        end = u.end / 1000\n",
    "        speaker = u.speaker\n",
    "        text = u.text.replace(\"\\n\", \" \")\n",
    "        f.write(f\"[ Start Time:{start} End Time:{end} ]\\nSpeaker {speaker}: {text}\\n\")\n",
    "\n",
    "\n",
    "print(f\"Wrote transcript to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691eac6d",
   "metadata": {},
   "source": [
    "ADD SPEAKER LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a8c9d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\"Speaker B\": \"Speaker B initiated the conversation by asking about Speaker A's favorite sport and NBA team. They then inquired about OKC's 2025 draft picks and strongly defended a player's performance in Dallas, questioning Speaker A's negative assessment of his stats.\",\n",
      "\"Speaker A\": \"Speaker A stated basketball as their favorite sport and OKC as their favorite NBA team, expressing disappointment in their 2025 draft picks. They adamantly disagreed with Speaker B's positive claims about a specific player's performance and stats, accusing Speaker B of propaganda.\"\n",
      "}\n",
      "```\n",
      "{'Speaker B': \"Speaker B initiated the conversation by asking about Speaker A's favorite sport and NBA team. They then inquired about OKC's 2025 draft picks and strongly defended a player's performance in Dallas, questioning Speaker A's negative assessment of his stats.\", 'Speaker A': \"Speaker A stated basketball as their favorite sport and OKC as their favorite NBA team, expressing disappointment in their 2025 draft picks. They adamantly disagreed with Speaker B's positive claims about a specific player's performance and stats, accusing Speaker B of propaganda.\"}\n",
      "\n",
      "üîç Identify Speakers\n",
      "============================================================\n",
      "\n",
      "üó£Ô∏è Speaker B talked about:\n",
      "   Speaker B initiated the conversation by asking about Speaker A's favorite sport and NBA team. They then inquired about OKC's 2025 draft picks and strongly defended a player's performance in Dallas, questioning Speaker A's negative assessment of his stats.\n",
      "\n",
      "üó£Ô∏è Speaker A talked about:\n",
      "   Speaker A stated basketball as their favorite sport and OKC as their favorite NBA team, expressing disappointment in their 2025 draft picks. They adamantly disagreed with Speaker B's positive claims about a specific player's performance and stats, accusing Speaker B of propaganda.\n",
      "============================================================\n",
      "\n",
      "‚úÖ Final Speaker Mapping:\n",
      "{\n",
      "  \"Speaker B\": \"Andre Cole\",\n",
      "  \"Speaker A\": \"Adil Gazder\"\n",
      "}\n",
      "üéØ Named transcript saved to namedREALTIME_transcript.txt\n"
     ]
    }
   ],
   "source": [
    "from Named_Transcript import rename_speakers_in_transcript\n",
    "\n",
    "labeled_transcript_path= rename_speakers_in_transcript(out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4f479",
   "metadata": {},
   "source": [
    "CONVERSATION JSON (FOR MINDMAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "881b19ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mind map JSON generated and saved to mindmap.json\n"
     ]
    }
   ],
   "source": [
    "from LLM_json_generator import generate_conversation_mindmap_json\n",
    "import json\n",
    "\n",
    "# CHANGE THIS TO LABELLED TRANSCRIPT FILE\n",
    "transcript_path = \"namedREALTIME_transcript.txt\"\n",
    "\n",
    "with open(transcript_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    transcript_text = f.read()\n",
    "\n",
    "mindmap_data = generate_conversation_mindmap_json(transcript_text, source_file=transcript_path)\n",
    "\n",
    "output_path = \"mindmap.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mindmap_data, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Mind map JSON generated and saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02541087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mindmap saved to digital_transformation_mindmap.html\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "# import networkx as nx\n",
    "# from pyvis.network import Network\n",
    "\n",
    "# # ------------------- Build Graph from Conversation JSON -------------------\n",
    "\n",
    "# def build_mindmap_graph(conversation_json):\n",
    "#     \"\"\"\n",
    "#     Build a graph where:\n",
    "#     - Main topics are nodes\n",
    "#     - Subtopics are nodes\n",
    "#     - Edges represent introduction or discussion\n",
    "#     - Relationships are edges with types\n",
    "#     \"\"\"\n",
    "#     G = nx.DiGraph()\n",
    "    \n",
    "#     # Add main topics\n",
    "#     for topic in conversation_json.get(\"main_topics\", []):\n",
    "#         topic_name = topic[\"topic\"]\n",
    "#         G.add_node(topic_name, label=topic_name, type=\"topic\", introduced_by=topic[\"introduced_by\"], sentiment=topic[\"sentiment\"])\n",
    "        \n",
    "#         # Add subtopics\n",
    "#         for sub in topic.get(\"subtopics\", []):\n",
    "#             sub_name = sub[\"subtopic\"]\n",
    "#             G.add_node(sub_name, label=sub_name, type=\"subtopic\", introduced_by=sub[\"introduced_by\"], sentiment=sub[\"sentiment\"])\n",
    "            \n",
    "#             # Edge from main topic to subtopic\n",
    "#             G.add_edge(topic_name, sub_name, label=sub[\"stance\"], introduced_by=sub[\"introduced_by\"])\n",
    "    \n",
    "#     # Add explicit relationships\n",
    "#     for rel in conversation_json.get(\"relationships\", []):\n",
    "#         G.add_edge(rel[\"from\"], rel[\"to\"], label=rel[\"type\"], introduced_by=rel[\"initiated_by\"])\n",
    "    \n",
    "#     return G\n",
    "\n",
    "# # ------------------- Visualize Graph with PyVis -------------------\n",
    "\n",
    "# def visualize_graph(G, output_html=\"mindmap.html\"):\n",
    "#     \"\"\"\n",
    "#     Create an interactive visualization of the graph using PyVis\n",
    "#     \"\"\"\n",
    "#     net = Network(height=\"750px\", width=\"100%\", directed=True, notebook=False)\n",
    "    \n",
    "#     # Add nodes\n",
    "#     for node, data in G.nodes(data=True):\n",
    "#         color_map = {\"topic\": \"#97C2FC\", \"subtopic\": \"#FFD700\"}  # Blue for main topic, yellow for subtopics\n",
    "#         sentiment_color = {\"positive\": \"#8BC34A\", \"neutral\": \"#FFC107\", \"negative\": \"#F44336\"}\n",
    "#         color = color_map.get(data.get(\"type\"), \"#D3D3D3\")\n",
    "#         color = sentiment_color.get(data.get(\"sentiment\"), color)\n",
    "        \n",
    "#         title = f\"{data.get('label')}<br>Introduced by: {data.get('introduced_by')}<br>Sentiment: {data.get('sentiment')}\"\n",
    "#         net.add_node(node, label=data.get(\"label\"), title=title, color=color)\n",
    "    \n",
    "#     # Add edges\n",
    "#     for u, v, data in G.edges(data=True):\n",
    "#         label = data.get(\"label\", \"\")\n",
    "#         net.add_edge(u, v, label=label, title=f\"{label} (by {data.get('introduced_by', 'unknown')})\")\n",
    "    \n",
    "#     # Generate interactive HTML\n",
    "#     #net.show(output_html)\n",
    "#     net.write_html(output_html)\n",
    "#     print(f\"‚úÖ Mindmap saved to {output_html}\")\n",
    "\n",
    "# # ------------------- Example Usage -------------------\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Load your JSON\n",
    "#     with open(\"mindmap.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#         conversation_json = json.load(f)\n",
    "    \n",
    "#     # Build graph\n",
    "#     G = build_mindmap_graph(conversation_json)\n",
    "    \n",
    "#     # Visualize and save HTML\n",
    "#     visualize_graph(G, \"digital_transformation_mindmap.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ad161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_mindmap_html_with_edge_attribution.py\n",
    "# Standalone HTML with NotebookLM-style layout and SPEAKER ATTRIBUTION ON EDGES (no participant nodes)\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = \"mindmap.json\"\n",
    "OUT_HTML  = \"Final_mindmap_app.html\"\n",
    "\n",
    "data = json.loads(Path(DATA_PATH).read_text(encoding=\"utf-8\"))\n",
    "data_js = json.dumps(data, ensure_ascii=False)\n",
    "\n",
    "html_doc = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\"/>\n",
    "<title>Conversation Mind Map</title>\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/>\n",
    "<script src=\"https://unpkg.com/vis-network@9.1.7/dist/vis-network.min.js\"></script>\n",
    "<link href=\"https://unpkg.com/vis-network@9.1.7/styles/vis-network.min.css\" rel=\"stylesheet\"/>\n",
    "\n",
    "<style>\n",
    "  :root {{\n",
    "    --bg: #ffffff;\n",
    "    --fg: #263238;\n",
    "    --edge: #CFD8DC;\n",
    "    --root: #B2DFDB;\n",
    "    --topic: #C5CAE9;\n",
    "    --subtopic: #BBDEFB;\n",
    "    --leaf: #E1F5FE;\n",
    "    --highlight: #FFE082;\n",
    "  }}\n",
    "  body {{ margin:0; background:var(--bg); color:var(--fg); font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial; }}\n",
    "  .toolbar {{\n",
    "    display:flex; gap:.75rem; flex-wrap:wrap; align-items:center;\n",
    "    padding:.75rem 1rem; border-bottom:1px solid #ECEFF1; position:sticky; top:0; background:rgba(255,255,255,.97); z-index:10;\n",
    "  }}\n",
    "  .toolbar label {{ font-size:.9rem; opacity:.9; }}\n",
    "  .toolbar input[type=\"range\"] {{ width:160px; vertical-align:middle; }}\n",
    "  .toolbar input[type=\"text\"] {{ width:220px; padding:.4rem .55rem; border:1px solid #ECEFF1; border-radius:8px; }}\n",
    "  .toolbar select {{ padding:.35rem .5rem; border:1px solid #ECEFF1; border-radius:8px; }}\n",
    "  .pill {{ display:inline-block; padding:.15rem .45rem; font-size:.75rem; border-radius:999px; background:#EEF2F7; margin-left:.35rem; }}\n",
    "  #graph {{ height: calc(100vh - 64px); }}\n",
    "  .note {{ padding:.35rem 1rem; font-size:.85rem; color:#607D8B; border-top:1px dashed #ECEFF1; }}\n",
    "</style>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "  <div class=\"toolbar\">\n",
    "    <label>Branch\n",
    "      <select id=\"topic\"></select>\n",
    "    </label>\n",
    "\n",
    "    <label>Depth\n",
    "      <input id=\"depth\" type=\"range\" min=\"1\" max=\"8\" step=\"1\" value=\"3\"/>\n",
    "      <span id=\"depthVal\" class=\"pill\">3</span>\n",
    "    </label>\n",
    "\n",
    "    <label>Wrap\n",
    "      <input id=\"wrap\" type=\"range\" min=\"14\" max=\"36\" step=\"1\" value=\"22\"/>\n",
    "      <span id=\"wrapVal\" class=\"pill\">22</span>\n",
    "    </label>\n",
    "\n",
    "    <label>Layout\n",
    "      <select id=\"direction\">\n",
    "        <option value=\"LR\" selected>Left ‚Üí Right</option>\n",
    "        <option value=\"UD\">Top ‚Üí Down</option>\n",
    "      </select>\n",
    "    </label>\n",
    "\n",
    "    <label><input id=\"hideX\" type=\"checkbox\" checked/> Hide cross-links</label>\n",
    "    <label><input id=\"edgeLabels\" type=\"checkbox\" checked/> Show speaker labels on edges</label>\n",
    "\n",
    "    <label>Highlight\n",
    "      <input id=\"search\" type=\"text\" placeholder=\"type to highlight‚Ä¶\"/>\n",
    "    </label>\n",
    "\n",
    "    <span id=\"stats\" class=\"pill\"></span>\n",
    "  </div>\n",
    "\n",
    "  <div id=\"graph\"></div>\n",
    "  <div class=\"note\">Tip: Choose one branch (topic) and keep depth at 2‚Äì3 for clarity. Toggle ‚ÄúShow speaker labels‚Äù to see who introduced/discussed each node.</div>\n",
    "\n",
    "<script>\n",
    "  // -------- Embedded Data --------\n",
    "  const DATA = {data_js};\n",
    "\n",
    "  // -------- UI refs --------\n",
    "  const topicSel   = document.getElementById('topic');\n",
    "  const depthEl    = document.getElementById('depth');\n",
    "  const depthVal   = document.getElementById('depthVal');\n",
    "  const wrapEl     = document.getElementById('wrap');\n",
    "  const wrapVal    = document.getElementById('wrapVal');\n",
    "  const dirEl      = document.getElementById('direction');\n",
    "  const hideX      = document.getElementById('hideX');\n",
    "  const edgeLabels = document.getElementById('edgeLabels');\n",
    "  const searchEl   = document.getElementById('search');\n",
    "  const statsEl    = document.getElementById('stats');\n",
    "\n",
    "  // Populate topics\n",
    "  const TOPICS = [\"All Topics\", ...(DATA.main_topics||[]).map(t => t.topic).filter(Boolean)];\n",
    "  TOPICS.forEach(t => {{\n",
    "    const opt = document.createElement('option');\n",
    "    opt.value = t; opt.textContent = t;\n",
    "    topicSel.appendChild(opt);\n",
    "  }});\n",
    "\n",
    "  depthEl.addEventListener('input', () => depthVal.textContent = depthEl.value);\n",
    "  wrapEl .addEventListener('input', () => wrapVal.textContent  = wrapEl.value);\n",
    "\n",
    "  // -------- Utils --------\n",
    "  function wrapLabel(s, width) {{\n",
    "    s = (s||\"\").trim().replace(/\\\\s+/g, \" \");\n",
    "    if (s.length <= width) return s;\n",
    "    const out = []; let line = [], ln = 0;\n",
    "    for (const w of s.split(\" \")) {{\n",
    "      const extra = line.length ? 1 : 0;\n",
    "      if (ln + w.length + extra > width) {{\n",
    "        out.push(line.join(\" \")); line=[w]; ln = w.length;\n",
    "      }} else {{ line.push(w); ln += w.length + extra; }}\n",
    "    }}\n",
    "    if (line.length) out.push(line.join(\" \"));\n",
    "    return out.join(\"<br>\");\n",
    "  }}\n",
    "\n",
    "  function tint(hex, sentiment) {{\n",
    "    if (!sentiment || sentiment === \"neutral\") return hex;\n",
    "    const r = parseInt(hex.slice(1,3),16), g=parseInt(hex.slice(3,5),16), b=parseInt(hex.slice(5,7),16);\n",
    "    let R=r,G=g,B=b;\n",
    "    if (sentiment === \"positive\") {{ R=Math.min(255, Math.round(r*1.10)); G=Math.min(255, Math.round(g*1.10)); B=Math.min(255, Math.round(b*1.10)); }}\n",
    "    if (sentiment === \"negative\") {{ R=Math.round(r*0.80); G=Math.round(g*0.80); B=Math.round(b*0.80); }}\n",
    "    return \"#\" + [R,G,B].map(v => v.toString(16).padStart(2,\"0\")).join(\"\");\n",
    "  }}\n",
    "\n",
    "  function truncateList(list, maxItems=3) {{\n",
    "    if (!Array.isArray(list)) return \"\";\n",
    "    const items = list.filter(Boolean);\n",
    "    if (items.length <= maxItems) return items.join(\", \");\n",
    "    return items.slice(0, maxItems).join(\", \") + \" +\" + (items.length - maxItems);\n",
    "  }}\n",
    "\n",
    "  // -------- Build graph data (edge attribution) --------\n",
    "  function buildData(opts) {{\n",
    "    const {{\n",
    "      selectedTopic = \"All Topics\",\n",
    "      maxDepth = 3,\n",
    "      hideCrosslinks = true,\n",
    "      wrap = 22,\n",
    "      showEdgeLabels = true\n",
    "    }} = opts;\n",
    "\n",
    "    const nodes = new vis.DataSet();\n",
    "    const edges = new vis.DataSet();\n",
    "\n",
    "    const palette = {{\n",
    "      root:     getComputedStyle(document.documentElement).getPropertyValue('--root').trim(),\n",
    "      topic:    getComputedStyle(document.documentElement).getPropertyValue('--topic').trim(),\n",
    "      subtopic: getComputedStyle(document.documentElement).getPropertyValue('--subtopic').trim(),\n",
    "      leaf:     getComputedStyle(document.documentElement).getPropertyValue('--leaf').trim()\n",
    "    }};\n",
    "\n",
    "    const addNode = (id, role, label, sentiment) => {{\n",
    "      if (!id || nodes.get(id)) return;\n",
    "      const color = tint(palette[role] || palette.leaf, sentiment);\n",
    "      nodes.add({{\n",
    "        id,\n",
    "        label: wrapLabel(label||id, wrap),\n",
    "        title: label||id,\n",
    "        color,\n",
    "        shape: \"box\",\n",
    "        margin: 10,\n",
    "        font: {{ multi: \"html\", size: 14 }}\n",
    "      }});\n",
    "    }};\n",
    "\n",
    "    const addEdge = (from, to, label, title) => {{\n",
    "      if (!from || !to) return;\n",
    "      const e = {{ from, to }};\n",
    "      if (showEdgeLabels && label) e.label = label;\n",
    "      if (title) e.title = title;\n",
    "      edges.add(e);\n",
    "    }};\n",
    "\n",
    "    const root = DATA.root || DATA.title || \"Mind Map\";\n",
    "    addNode(root, \"root\", root);\n",
    "\n",
    "    // Edge attribution for topics: \"introduced by ...\"\n",
    "    function addTopicBranch(topicObj) {{\n",
    "      const tname = topicObj.topic;\n",
    "      addNode(tname, \"topic\", tname, topicObj.sentiment);\n",
    "\n",
    "      let topicEdgeLabel = \"\";\n",
    "      let topicEdgeTitle = \"\";\n",
    "      const introBy = topicObj.introduced_by;\n",
    "      const introAt = topicObj.introduced_at;\n",
    "      if (introBy) {{\n",
    "        topicEdgeLabel = \"introduced by \" + introBy;\n",
    "        topicEdgeTitle = \"<b>introduced by</b>: \" + introBy + (introAt ? \"<br><b>at</b>: \" + introAt : \"\");\n",
    "      }}\n",
    "      addEdge(root, tname, topicEdgeLabel, topicEdgeTitle);\n",
    "\n",
    "      // Subtopics: attribution from discussed_by / stance goes on the edge Topic‚ÜíSubtopic\n",
    "      for (const s of (topicObj.subtopics || [])) {{\n",
    "        const sname = s.subtopic;\n",
    "        addNode(sname, \"subtopic\", sname, s.sentiment);\n",
    "\n",
    "        const whoList = (s.discussed_by || []).filter(Boolean);\n",
    "        const stance  = s.stance;\n",
    "        const labelWho = truncateList(whoList, 2);\n",
    "        let subEdgeLabel = \"\";\n",
    "        let subEdgeTitle = \"\";\n",
    "        if (labelWho || stance) {{\n",
    "          const parts = [];\n",
    "          if (labelWho) parts.push(\"discussed by \" + labelWho);\n",
    "          if (stance)   parts.push(\"stance: \" + stance);\n",
    "          subEdgeLabel = parts.join(\" ¬∑ \");\n",
    "          subEdgeTitle = parts.map(p => \"<b>\" + p.split(\":\")[0] + \"</b>: \" + (p.split(\":\")[1] || \"\").trim()).join(\"<br>\");\n",
    "        }}\n",
    "        addEdge(tname, sname, subEdgeLabel, subEdgeTitle);\n",
    "\n",
    "        // Optional leaves (entities/notes) under Subtopic (no attribution here to keep it clean)\n",
    "        const entities = Array.isArray(s.entities) ? s.entities : [];\n",
    "        const notes    = Array.isArray(s.notes) ? s.notes : [];\n",
    "        const leaves   = [];\n",
    "        for (const x of entities) {{\n",
    "          if (typeof x === 'string') leaves.push(x);\n",
    "          else if (x && (x.name || x.text)) leaves.push(x.name || x.text);\n",
    "        }}\n",
    "        for (const y of notes) {{\n",
    "          if (typeof y === 'string') leaves.push(y);\n",
    "          else if (y && (y.name || y.text)) leaves.push(y.name || y.text);\n",
    "        }}\n",
    "        for (const leaf of leaves) {{\n",
    "          addNode(leaf, \"leaf\", leaf, null);\n",
    "          addEdge(sname, leaf, \"\", \"\");\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "\n",
    "    if (selectedTopic === \"All Topics\") {{\n",
    "      for (const t of (DATA.main_topics || [])) addTopicBranch(t);\n",
    "    }} else {{\n",
    "      const t = (DATA.main_topics || []).find(x => x.topic === selectedTopic);\n",
    "      if (t) addTopicBranch(t);\n",
    "    }}\n",
    "\n",
    "    // Cross-link relationships (attribution on those edges too), unless hidden\n",
    "    if (!hideCrosslinks) {{\n",
    "      for (const r of (DATA.relationships || [])) {{\n",
    "        const frm = r.from, to = r.to; if (!frm || !to) continue;\n",
    "        // Ensure nodes exist (type inference is minimal here)\n",
    "        addNode(frm, \"leaf\", frm, null);\n",
    "        addNode(to,  \"leaf\", to,  null);\n",
    "        let lbl = \"\";\n",
    "        let ttl = \"\";\n",
    "        if (r.type) lbl = r.type;\n",
    "        const by = r.initiated_by, at = r.initiated_at;\n",
    "        const extras = [];\n",
    "        if (by) extras.push(\"by \" + by);\n",
    "        if (at) extras.push(\"at \" + at);\n",
    "        if (extras.length) lbl = (lbl ? lbl + \" ¬∑ \" : \"\") + extras.join(\" \");\n",
    "        if (r.type) ttl += \"<b>type</b>: \" + r.type;\n",
    "        if (by)     ttl += (ttl ? \"<br>\" : \"\") + \"<b>by</b>: \" + by;\n",
    "        if (at)     ttl += (ttl ? \"<br>\" : \"\") + \"<b>at</b>: \" + at;\n",
    "        addEdge(frm, to, lbl, ttl);\n",
    "      }}\n",
    "    }}\n",
    "\n",
    "    // Depth prune (root-out)\n",
    "    const adj = new Map(); nodes.forEach(n => adj.set(n.id, []));\n",
    "    edges.forEach(e => {{ if (adj.has(e.from)) adj.get(e.from).push(e.to); }});\n",
    "    const keep = new Set([root]); let frontier = [root], d=0;\n",
    "    while (frontier.length && d < maxDepth) {{\n",
    "      const nxt = [];\n",
    "      for (const u of frontier) {{\n",
    "        const kids = adj.get(u) || [];\n",
    "        for (const v of kids) if (!keep.has(v)) {{ keep.add(v); nxt.push(v); }}\n",
    "      }}\n",
    "      frontier = nxt; d += 1;\n",
    "    }}\n",
    "    const n2 = new vis.DataSet(nodes.get().filter(n => keep.has(n.id)));\n",
    "    const kept = new Set(n2.getIds());\n",
    "    const e2 = new vis.DataSet(edges.get().filter(e => kept.has(e.from) && kept.has(e.to)));\n",
    "\n",
    "    return {{ nodes: n2, edges: e2 }};\n",
    "  }}\n",
    "\n",
    "  // -------- Render --------\n",
    "  const container = document.getElementById('graph');\n",
    "  let network = null;\n",
    "\n",
    "  function render() {{\n",
    "    const opts = {{\n",
    "      selectedTopic: topicSel.value || \"All Topics\",\n",
    "      maxDepth: parseInt(depthEl.value, 10),\n",
    "      hideCrosslinks: hideX.checked,\n",
    "      wrap: parseInt(wrapEl.value, 10),\n",
    "      showEdgeLabels: edgeLabels.checked\n",
    "    }};\n",
    "    const data = buildData(opts);\n",
    "\n",
    "    const options = {{\n",
    "      layout: {{\n",
    "        hierarchical: {{\n",
    "          enabled: true,\n",
    "          direction: dirEl.value,   // \"LR\" or \"UD\"\n",
    "          sortMethod: \"hubsize\",\n",
    "          levelSeparation: 230,\n",
    "          nodeSpacing: 210,\n",
    "          treeSpacing: 280\n",
    "        }}\n",
    "      }},\n",
    "      physics: {{ enabled: false }},\n",
    "      nodes: {{\n",
    "        shape: \"box\",\n",
    "        color: {{\n",
    "          border: \"#ECEFF1\",\n",
    "          highlight: {{ border: \"#90CAF9\", background: \"#E3F2FD\" }}\n",
    "        }},\n",
    "        widthConstraint: {{ maximum: 260 }}\n",
    "      }},\n",
    "      edges: {{\n",
    "        smooth: {{ type: \"continuous\" }},\n",
    "        color: {{ color: getComputedStyle(document.documentElement).getPropertyValue('--edge').trim() }},\n",
    "        arrows: {{ to: {{ enabled: false }} }},\n",
    "        font: {{ align: \"top\", size: 11, color: \"#546E7A\", background: \"#FAFAFA\" }}\n",
    "      }},\n",
    "      interaction: {{ hover: true, tooltipDelay: 80 }}\n",
    "    }};\n",
    "\n",
    "    container.innerHTML = \"\";\n",
    "    network = new vis.Network(container, data, options);\n",
    "\n",
    "    // Client-side highlight\n",
    "    const q = (searchEl.value || \"\").trim().toLowerCase();\n",
    "    if (q) {{\n",
    "      const ids = data.nodes.getIds();\n",
    "      for (const id of ids) {{\n",
    "        const n = data.nodes.get(id);\n",
    "        const lbl = (n.title || \"\").toLowerCase();\n",
    "        if (lbl.includes(q)) {{\n",
    "          data.nodes.update({{ id, color: getComputedStyle(document.documentElement).getPropertyValue('--highlight').trim() }});\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "\n",
    "    statsEl.textContent = data.nodes.length + \" nodes ¬∑ \" + data.edges.length + \" edges\";\n",
    "  }}\n",
    "\n",
    "  // Events\n",
    "  [topicSel, depthEl, wrapEl, dirEl, hideX, edgeLabels].forEach(el => el.addEventListener('input', render));\n",
    "  searchEl.addEventListener('input', render);\n",
    "\n",
    "  // Init\n",
    "  topicSel.value = \"All Topics\";\n",
    "  render();\n",
    "</script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "Path(OUT_HTML).write_text(html_doc, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Wrote {OUT_HTML}. Open it in your browser.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61e329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ffb1867",
   "metadata": {},
   "source": [
    "FOR SPEAKER IDENTIFICATION AND CONTEXTUAL INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258081b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 unique speakers:\n",
      "\n",
      " 1. Andre Cole\n",
      " 2. Adil Gazder\n",
      "\n",
      "[+] Fetching: Andre Cole\n",
      "\n",
      "[+] Fetching: Adil Gazder\n",
      "\n",
      "‚úÖ Done.\n",
      "Profiles saved under: out_speakers/profiles\n",
      "Summary: out_speakers/speakers_summary.json\n"
     ]
    }
   ],
   "source": [
    "from speaker_identify import extract_speakers, normalize_header_to_name, unique_preserve_order\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from peoplestalk import google_search_person\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"CUSTOM_SEARCH_API_KEY\", \"\").strip()\n",
    "CX = os.getenv(\"CUSTOM_SEARCH_ENGINE_ID\", \"\").strip()\n",
    "\n",
    "### REPLACE WITH LABELLED TRANSCRIPT FILE\n",
    "input_path = \"namedREALTIME_transcript.txt\"  # transcript file\n",
    "out_dir = \"out_speakers\"  # where to save outputs\n",
    "pages = 1  # Google pages per speaker (10 results/page)\n",
    "pause = 1.5  # seconds between API calls\n",
    "query_template = '\"{name}\"'  # search pattern\n",
    "dry_run = False  # True = skip Google API calls (for testing)\n",
    "\n",
    "text = Path(input_path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "raw_headers = extract_speakers(text)\n",
    "names = [normalize_header_to_name(h) for h in raw_headers if h.strip()]\n",
    "speakers = unique_preserve_order(names)\n",
    "# print(text)\n",
    "# print(raw_headers)\n",
    "# print(text)\n",
    "# print(speakers)\n",
    "\n",
    "out_dir = Path(out_dir)\n",
    "(out_dir / \"profiles\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Found {len(speakers)} unique speakers:\\n\")\n",
    "for i, s in enumerate(speakers, 1):\n",
    "    print(f\"{i:>2}. {s}\")\n",
    "\n",
    "summary = {\n",
    "    \"input\": input_path,\n",
    "    \"total_unique_speakers\": len(speakers),\n",
    "    \"query_template\": query_template,\n",
    "    \"pages\": pages,\n",
    "    \"pause\": pause,\n",
    "    \"speakers\": [],\n",
    "    \"generated_at\": time.time(),\n",
    "}\n",
    "\n",
    "if dry_run:\n",
    "    Path(out_dir / \"speakers_summary.json\").write_text(\n",
    "        json.dumps(summary, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
    "    )\n",
    "    print(f\"\\n--dry-run=True: wrote only {out_dir/'speakers_summary.json'}\")\n",
    "else:\n",
    "    if not API_KEY or not CX:\n",
    "        raise SystemExit(\"‚ùå Missing CUSTOM_SEARCH_API_KEY or CUSTOM_SEARCH_ENGINE_ID (.env)\")\n",
    "\n",
    "    for name in speakers:\n",
    "        print(f\"\\n[+] Fetching: {name}\")\n",
    "        try:\n",
    "            info = google_search_person(\n",
    "                person_name=name,\n",
    "                # api_key=API_KEY,\n",
    "                # cx=CX,\n",
    "                num_pages=pages,\n",
    "                pause=pause,\n",
    "                # query_template=query_template,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚úó Error for {name}: {e}\")\n",
    "            info = {\n",
    "                \"query\": name,\n",
    "                \"rendered_query\": query_template.format(name=name),\n",
    "                \"total_results\": 0,\n",
    "                \"texts\": [],\n",
    "                \"links\": [],\n",
    "                \"error\": str(e),\n",
    "            }\n",
    "\n",
    "        slug = re.sub(r\"[^0-9A-Za-z\\-_]+\", \"_\", name).strip(\"_\")\n",
    "        out_file = out_dir / \"profiles\" / f\"{slug}_info.json\"\n",
    "        out_file.write_text(json.dumps(info, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "        summary[\"speakers\"].append({\n",
    "            \"name\": name,\n",
    "            \"file\": str(out_file),\n",
    "            \"total_results\": info.get(\"total_results\", 0),\n",
    "        })\n",
    "\n",
    "    Path(out_dir / \"speakers_summary.json\").write_text(\n",
    "        json.dumps(summary, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚úÖ Done.\\nProfiles saved under: {out_dir/'profiles'}\\nSummary: {out_dir/'speakers_summary.json'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86219dc0",
   "metadata": {},
   "source": [
    "SEND TO FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d74e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asus/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing out_speakers/profiles/Michelle_Tandler_info.json...\n",
      "Processing out_speakers/profiles/Paul_Varga_info.json...\n",
      "Processing out_speakers/profiles/Mark_Cuban_info.json...\n",
      "Processing out_speakers/profiles/Joe_Rogan_info.json...\n",
      "Processing out_speakers/profiles/Adil_Gazder_info.json...\n",
      "Processing out_speakers/profiles/Neha_Senthil_info.json...\n",
      "Processing out_speakers/profiles/Bill_Gates_info.json...\n",
      "Processing out_speakers/profiles/Pranshul_Bhatnagar_info.json...\n",
      "Processing out_speakers/profiles/Andrew_Garfield_info.json...\n",
      "Processing out_speakers/profiles/Kevin_O_Leary_info.json...\n",
      "Processing out_speakers/profiles/Andre_Cole_info.json...\n",
      "Processing out_speakers/profiles/James_Sinegal_info.json...\n",
      "Processing out_speakers/profiles/Daymond_John_info.json...\n",
      "Processing out_speakers/profiles/Lex_Fridman_info.json...\n",
      "Processing out_speakers/profiles/Paul_Hudson_info.json...\n",
      "Processing out_speakers/profiles/Peter_Thiel_info.json...\n",
      "Processing out_speakers/profiles/Lewis_Hamilton_info.json...\n",
      "Processing out_speakers/profiles/Mobasserul_Haque_info.json...\n",
      "Processing out_speakers/profiles/Aravind_Srinivas_info.json...\n",
      "________________\n",
      "[{'id': '97bd5658-eccf-45e6-991f-e21ddf3702d4', 'text': 'Topic: Favorite Sport introduced by Andre Cole at 00:00:01. Sentiment: neutral.', 'metadata': {'type': 'topic', 'introduced_by': 'Andre Cole', 'person_id': 'andre_cole'}}, {'id': '6ab1aab5-a9fc-4dfc-8107-8532fde18df1', 'text': 'Subtopic: Basketball as Favorite Sport introduced by Adil Gazder (support toward Favorite Sport). Discussed by Adil Gazder. Sentiment: neutral', 'metadata': {'type': 'subtopic', 'introduced_by': 'Adil Gazder', 'person_id': 'adil_gazder'}}, {'id': 'cc070274-9454-4966-9f0b-2de3cedd4af7', 'text': 'Topic: NBA Fandom introduced by Andre Cole at 00:00:05. Sentiment: neutral.', 'metadata': {'type': 'topic', 'introduced_by': 'Andre Cole', 'person_id': 'andre_cole'}}, {'id': 'fd4f2d82-3d67-4e22-8a5c-808472df9c2f', 'text': 'Subtopic: Following NBA introduced by Andre Cole (question toward NBA Fandom). Discussed by Andre Cole, Adil Gazder. Sentiment: neutral', 'metadata': {'type': 'subtopic', 'introduced_by': 'Andre Cole', 'person_id': 'andre_cole'}}, {'id': '85df7e61-7e51-4ad0-95d0-8bc71f7a995e', 'text': 'Subtopic: OKC as Favorite Team introduced by Andre Cole (question toward NBA Fandom). Discussed by Andre Cole, Adil Gazder. Sentiment: neutral', 'metadata': {'type': 'subtopic', 'introduced_by': 'Andre Cole', 'person_id': 'andre_cole'}}, {'id': '36273500-1df1-46ea-aee2-3e6cf0cd9664', 'text': 'Topic: OKC Draft Picks introduced by Andre Cole at 00:00:10. Sentiment: neutral.', 'metadata': {'type': 'topic', 'introduced_by': 'Andre Cole', 'person_id': 'andre_cole'}}, {'id': 'ff0f03b7-a0d1-447f-96f7-d99f121284d7', 'text': 'Subtopic: Quantity of Draft Picks (25) introduced by Andre Cole (question toward OKC Draft Picks). Discussed by Andre Cole, Adil Gazder. Sentiment: neutral', 'metadata': {'type': 'subtopic', 'introduced_by': 'Andre Cole', 'person_id': 'andre_cole'}}, {'id': '8207bc7a-020d-4ab7-b08c-1e69e935e102', 'text': 'Subtopic: Quality of Draft Picks (Second Rounders) introduced by Adil Gazder (elaboration toward Quantity of Draft Picks (25)). Discussed by Adil Gazder. Sentiment: neutral', 'metadata': {'type': 'subtopic', 'introduced_by': 'Adil Gazder', 'person_id': 'adil_gazder'}}, {'id': 'e00cd607-2631-44e7-b493-3602d98f7124', 'text': 'Subtopic: Lack of Top Talent from Good Schools introduced by Adil Gazder (elaboration toward Quality of Draft Picks (Second Rounders)). Discussed by Adil Gazder, Andre Cole. Sentiment: negative', 'metadata': {'type': 'subtopic', 'introduced_by': 'Adil Gazder', 'person_id': 'adil_gazder'}}, {'id': 'b504f457-0af7-48eb-8cc3-37e91b373a92', 'text': \"Topic: Cooper Flag's Performance introduced by Adil Gazder at 00:00:25. Sentiment: negative.\", 'metadata': {'type': 'topic', 'introduced_by': 'Adil Gazder', 'person_id': 'adil_gazder'}}, {'id': 'ebbc3431-3cab-4566-bf89-926f3ed66346', 'text': \"Subtopic: Cooper Flag's Poor Performance in Dallas introduced by Adil Gazder (challenge toward Cooper Flag's Performance). Discussed by Adil Gazder. Sentiment: negative\", 'metadata': {'type': 'subtopic', 'introduced_by': 'Adil Gazder', 'person_id': 'adil_gazder'}}, {'id': '201f26eb-213b-4fc7-bd5f-7527cd51e589', 'text': \"Subtopic: Cooper Flag Playing Well introduced by Andre Cole (challenge toward Cooper Flag's Poor Performance in Dallas). Discussed by Andre Cole. Sentiment: positive\", 'metadata': {'type': 'subtopic', 'introduced_by': 'Andre Cole', 'person_id': 'andre_cole'}}, {'id': '5a4c79e8-94e6-4025-a468-9a2e7129117d', 'text': 'Subtopic: Performance vs. Game Outcomes introduced by Andre Cole (elaboration toward Cooper Flag Playing Well). Discussed by Andre Cole. Sentiment: neutral', 'metadata': {'type': 'subtopic', 'introduced_by': 'Andre Cole', 'person_id': 'andre_cole'}}, {'id': 'ee05a72f-c477-45f3-a06f-30e461f479a6', 'text': 'Subtopic: Plus/Minus Stats introduced by Adil Gazder (challenge toward Performance vs. Game Outcomes). Discussed by Adil Gazder. Sentiment: negative', 'metadata': {'type': 'subtopic', 'introduced_by': 'Adil Gazder', 'person_id': 'adil_gazder'}}, {'id': '3eb8c3ee-b725-40d5-98c8-d37756a9e7bf', 'text': 'Subtopic: Averaging 18 Points introduced by Andre Cole (challenge toward Plus/Minus Stats). Discussed by Andre Cole. Sentiment: positive', 'metadata': {'type': 'subtopic', 'introduced_by': 'Andre Cole', 'person_id': 'andre_cole'}}, {'id': 'c9dea15c-be75-4c7a-bc58-f3c602728466', 'text': 'Subtopic: Averaging 10 Points introduced by Adil Gazder (challenge toward Averaging 18 Points). Discussed by Adil Gazder. Sentiment: negative', 'metadata': {'type': 'subtopic', 'introduced_by': 'Adil Gazder', 'person_id': 'adil_gazder'}}, {'id': 'b3302bc3-4ca6-46b4-b171-c10902f649bd', 'text': 'Subtopic: Source of Information (Propaganda/Mavs Instagram) introduced by Adil Gazder (challenge toward Averaging 18 Points). Discussed by Adil Gazder, Andre Cole. Sentiment: negative', 'metadata': {'type': 'subtopic', 'introduced_by': 'Adil Gazder', 'person_id': 'adil_gazder'}}, {'id': 'a57717ed-23c3-47d9-8c49-dd56f5a90efc', 'text': 'Relationship: Basketball as Favorite Sport support Favorite Sport (initiated by Adil Gazder)', 'metadata': {'type': 'relationship'}}, {'id': 'b4545736-95f4-4d43-ab38-571b59ad5527', 'text': 'Relationship: Following NBA extension NBA Fandom (initiated by Andre Cole)', 'metadata': {'type': 'relationship'}}, {'id': 'f7de8b8e-e692-4393-89aa-f095b0dbb0a4', 'text': 'Relationship: OKC as Favorite Team extension NBA Fandom (initiated by Andre Cole)', 'metadata': {'type': 'relationship'}}, {'id': '435f2b5d-280b-450c-a8a5-0ec55fc3c72a', 'text': 'Relationship: Quantity of Draft Picks (25) extension OKC Draft Picks (initiated by Andre Cole)', 'metadata': {'type': 'relationship'}}, {'id': '9fa9c7fa-0385-456d-9562-e6817150fdaa', 'text': 'Relationship: Quality of Draft Picks (Second Rounders) elaboration Quantity of Draft Picks (25) (initiated by Adil Gazder)', 'metadata': {'type': 'relationship'}}, {'id': 'b37501b3-5dfc-4fdd-8485-2d2197c004cf', 'text': 'Relationship: Lack of Top Talent from Good Schools elaboration Quality of Draft Picks (Second Rounders) (initiated by Adil Gazder)', 'metadata': {'type': 'relationship'}}, {'id': '2daac11e-5b5c-4e91-8d99-047c8f0d6b58', 'text': \"Relationship: Cooper Flag's Poor Performance in Dallas elaboration Lack of Top Talent from Good Schools (initiated by Adil Gazder)\", 'metadata': {'type': 'relationship'}}, {'id': 'a8f14890-8028-497e-87bc-544f4ef3f5da', 'text': \"Relationship: Cooper Flag Playing Well challenge Cooper Flag's Poor Performance in Dallas (initiated by Andre Cole)\", 'metadata': {'type': 'relationship'}}, {'id': '8c188295-c543-4254-8232-d0bba1bc1876', 'text': 'Relationship: Performance vs. Game Outcomes elaboration Cooper Flag Playing Well (initiated by Andre Cole)', 'metadata': {'type': 'relationship'}}, {'id': '93000311-dbab-4305-bd10-92cd2281b614', 'text': 'Relationship: Plus/Minus Stats challenge Performance vs. Game Outcomes (initiated by Adil Gazder)', 'metadata': {'type': 'relationship'}}, {'id': '9ff0b74f-95aa-44a1-bd30-94589dedbae6', 'text': 'Relationship: Averaging 18 Points challenge Plus/Minus Stats (initiated by Andre Cole)', 'metadata': {'type': 'relationship'}}, {'id': '4bca2a77-a86d-44cd-8436-02a3eb1b193c', 'text': 'Relationship: Averaging 10 Points challenge Averaging 18 Points (initiated by Adil Gazder)', 'metadata': {'type': 'relationship'}}, {'id': '3bd151b6-0245-4f8b-b31b-1886ed95de46', 'text': 'Relationship: Source of Information (Propaganda/Mavs Instagram) challenge Averaging 18 Points (initiated by Adil Gazder)', 'metadata': {'type': 'relationship'}}]\n",
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "(30, 384)\n",
      "\n",
      "Enter your questions about the conversation (type 'exit' to quit):\n",
      "mindmap | None | Topic: NBA Fandom introduced by Andre Cole at 00:00:05. Sentiment: neutral....\n",
      "person_db | None | Joe Rogan (https://www.presidency.ucsb.edu/documents/interview-the-joe-rogan-experience): Interview ...\n",
      "mindmap | None | Topic: Favorite Sport introduced by Andre Cole at 00:00:01. Sentiment: neutral....\n",
      "mindmap | None | Topic: OKC Draft Picks introduced by Andre Cole at 00:00:10. Sentiment: neutral....\n",
      "person_db | None | Daymond John (https://lewishowes.com/podcast/e-daymond-john-rise-grind-habits-successful-business-li...\n",
      "person_db | None | Mark Cuban (https://www.reddit.com/r/IAmA/comments/15doqt/mark_cuban_this_is_my_ama/): Reddit - The ...\n",
      "\n",
      "üí° Answer:\n",
      " We discussed NBA fandom, favorite sports, OKC draft picks, an interview with Donald Trump on \"The Joe Rogan Experience,\" Daymond John's \"Rise and Grind\" podcast, and Mark Cuban's Reddit AMA.\n",
      "\n",
      "‚úÖ Chat History:\n",
      "====================\n",
      "Q: what did we talk about\n",
      "A: We discussed NBA fandom, favorite sports, OKC draft picks, an interview with Donald Trump on \"The Joe Rogan Experience,\" Daymond John's \"Rise and Grind\" podcast, and Mark Cuban's Reddit AMA.\n",
      "\n",
      "====================\n",
      "person_db | None | Adil Gazder (https://www.sciencedirect.com/science/article/abs/pii/S0921509322018147): Jan 18, 2023 ...\n",
      "person_db | None | Adil Gazder (https://www.facebook.com/adil.gazder.5/): Studied Mechanical engineering at Shiv Nadar ...\n",
      "person_db | None | Adil Gazder (https://dcid.sanford.duke.edu/blog/): Aug 11, 2025 ... Duke MIDS student Adil Gazder sh...\n",
      "mindmap | None | Relationship: Basketball as Favorite Sport support Favorite Sport (initiated by Adil Gazder)...\n",
      "mindmap | None | Relationship: Quality of Draft Picks (Second Rounders) elaboration Quantity of Draft Picks (25) (ini...\n",
      "mindmap | None | Relationship: Lack of Top Talent from Good Schools elaboration Quality of Draft Picks (Second Rounde...\n",
      "\n",
      "üí° Answer:\n",
      " Adil Gazder is a Duke MIDS student and Mechanical Engineering graduate from Shiv Nadar University. He is involved with the Climate Dialogue & Innovation Initiative, has contributed to scientific articles, and lives in Chennai, India. He also initiated discussions on topics like basketball as a favorite sport and the quality of NBA draft picks.\n",
      "\n",
      "‚úÖ Chat History:\n",
      "====================\n",
      "Q: what did we talk about\n",
      "A: We discussed NBA fandom, favorite sports, OKC draft picks, an interview with Donald Trump on \"The Joe Rogan Experience,\" Daymond John's \"Rise and Grind\" podcast, and Mark Cuban's Reddit AMA.\n",
      "\n",
      "Q: who is Adil\n",
      "A: Adil Gazder is a Duke MIDS student and Mechanical Engineering graduate from Shiv Nadar University. He is involved with the Climate Dialogue & Innovation Initiative, has contributed to scientific articles, and lives in Chennai, India. He also initiated discussions on topics like basketball as a favorite sport and the quality of NBA draft picks.\n",
      "\n",
      "====================\n",
      "person_db | None | Andre Cole (https://www.truvefit.com/andre-cole): Andr√© is a Bay Area-based performing artist and fi...\n",
      "person_db | None | Andre Cole (https://www.andrecole.com/): Bay Area-based dancer, choreographer, music & video produce...\n",
      "person_db | None | Andre Cole (https://www.instagram.com/andrecole/?hl=en): 938 followers ¬∑ 903 following ¬∑ 692 posts ¬∑...\n",
      "mindmap | None | Relationship: Following NBA extension NBA Fandom (initiated by Andre Cole)...\n",
      "mindmap | None | Relationship: OKC as Favorite Team extension NBA Fandom (initiated by Andre Cole)...\n",
      "mindmap | None | Topic: Favorite Sport introduced by Andre Cole at 00:00:01. Sentiment: neutral....\n",
      "\n",
      "üí° Answer:\n",
      " Andre Cole is a Bay Area-based performing artist and fitness enthusiast, working as an improv dancer, choreographer, drummer, youth dance educator, personal trainer, music & video producer/editor. He has edited an Emmy-nominated project and a 2x Webby winner. He initiated discussions about NBA fandom (with OKC as his favorite team) and his favorite sport.\n",
      "\n",
      "‚úÖ Chat History:\n",
      "====================\n",
      "Q: what did we talk about\n",
      "A: We discussed NBA fandom, favorite sports, OKC draft picks, an interview with Donald Trump on \"The Joe Rogan Experience,\" Daymond John's \"Rise and Grind\" podcast, and Mark Cuban's Reddit AMA.\n",
      "\n",
      "Q: who is Adil\n",
      "A: Adil Gazder is a Duke MIDS student and Mechanical Engineering graduate from Shiv Nadar University. He is involved with the Climate Dialogue & Innovation Initiative, has contributed to scientific articles, and lives in Chennai, India. He also initiated discussions on topics like basketball as a favorite sport and the quality of NBA draft picks.\n",
      "\n",
      "Q: Who is Andre\n",
      "A: Andre Cole is a Bay Area-based performing artist and fitness enthusiast, working as an improv dancer, choreographer, drummer, youth dance educator, personal trainer, music & video producer/editor. He has edited an Emmy-nominated project and a 2x Webby winner. He initiated discussions about NBA fandom (with OKC as his favorite team) and his favorite sport.\n",
      "\n",
      "====================\n",
      "person_db | None | Neha Senthil (https://www.facebook.com/100019675627391/photos/1617233655609140/): Facebook...\n",
      "person_db | None | Lex Fridman (https://lexfridman.com/podcast/): Lex Fridman Podcast - Lex Fridman Skip to content Thi...\n",
      "person_db | None | Neha Senthil (https://in.linkedin.com/in/neha-l-senthil): ...\n",
      "mindmap | None | Relationship: Source of Information (Propaganda/Mavs Instagram) challenge Averaging 18 Points (initi...\n",
      "mindmap | None | Subtopic: Source of Information (Propaganda/Mavs Instagram) introduced by Adil Gazder (challenge tow...\n",
      "mindmap | None | Subtopic: Averaging 10 Points introduced by Adil Gazder (challenge toward Averaging 18 Points). Disc...\n",
      "\n",
      "üí° Answer:\n",
      " Neha Senthil has a Facebook and LinkedIn profile. She was also involved in a discussion about \"Source of Information (Propaganda/Mavs Instagram)\" regarding a challenge toward \"Averaging 18 Points,\" which was initiated by Adil Gazder and discussed with Andre Cole.\n",
      "\n",
      "‚úÖ Chat History:\n",
      "====================\n",
      "Q: what did we talk about\n",
      "A: We discussed NBA fandom, favorite sports, OKC draft picks, an interview with Donald Trump on \"The Joe Rogan Experience,\" Daymond John's \"Rise and Grind\" podcast, and Mark Cuban's Reddit AMA.\n",
      "\n",
      "Q: who is Adil\n",
      "A: Adil Gazder is a Duke MIDS student and Mechanical Engineering graduate from Shiv Nadar University. He is involved with the Climate Dialogue & Innovation Initiative, has contributed to scientific articles, and lives in Chennai, India. He also initiated discussions on topics like basketball as a favorite sport and the quality of NBA draft picks.\n",
      "\n",
      "Q: Who is Andre\n",
      "A: Andre Cole is a Bay Area-based performing artist and fitness enthusiast, working as an improv dancer, choreographer, drummer, youth dance educator, personal trainer, music & video producer/editor. He has edited an Emmy-nominated project and a 2x Webby winner. He initiated discussions about NBA fandom (with OKC as his favorite team) and his favorite sport.\n",
      "\n",
      "Q: \n",
      "A: Neha Senthil has a Facebook and LinkedIn profile. She was also involved in a discussion about \"Source of Information (Propaganda/Mavs Instagram)\" regarding a challenge toward \"Averaging 18 Points,\" which was initiated by Adil Gazder and discussed with Andre Cole.\n",
      "\n",
      "====================\n",
      "person_db | None | Neha Senthil (https://www.facebook.com/100019675627391/photos/1617233655609140/): Facebook...\n",
      "person_db | None | Lex Fridman (https://lexfridman.com/podcast/): Lex Fridman Podcast - Lex Fridman Skip to content Thi...\n",
      "person_db | None | Neha Senthil (https://in.linkedin.com/in/neha-l-senthil): ...\n",
      "mindmap | None | Relationship: Source of Information (Propaganda/Mavs Instagram) challenge Averaging 18 Points (initi...\n",
      "mindmap | None | Subtopic: Source of Information (Propaganda/Mavs Instagram) introduced by Adil Gazder (challenge tow...\n",
      "mindmap | None | Subtopic: Averaging 10 Points introduced by Adil Gazder (challenge toward Averaging 18 Points). Disc...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33msource\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.get(\u001b[33m'\u001b[39m\u001b[33mperson_id\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m100\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# RAG answer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m answer = \u001b[43mmake_rag_make_sense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müí° Answer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, answer)\n\u001b[32m     54\u001b[39m history[query] = answer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DukeAIHack25/RAG_FRAMEWORK.py:245\u001b[39m, in \u001b[36mmake_rag_make_sense\u001b[39m\u001b[34m(query, retrieved_chunks, history)\u001b[39m\n\u001b[32m    230\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[33mYou have the following context to help answer the user\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms query. Use Chat history to maintain continuity. Keep the answer concise and short:\u001b[39m\n\u001b[32m    232\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    242\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    244\u001b[39m     model = genai.GenerativeModel(\u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/google/generativeai/generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:75\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(callable_)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror_remapped_callable\u001b[39m(*args, **kwargs):\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/grpc/_interceptor.py:276\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    269\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/grpc/_interceptor.py:328\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m    326\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys.exc_info()[\u001b[32m2\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interceptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call.result(), call\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:79\u001b[39m, in \u001b[36m_LoggingClientInterceptor.intercept_unary_unary\u001b[39m\u001b[34m(self, continuation, client_call_details, request)\u001b[39m\n\u001b[32m     64\u001b[39m     grpc_request = {\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m\"\u001b[39m: request_payload,\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrequestMethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgrpc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m     _LOGGER.debug(\n\u001b[32m     70\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details.method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m         extra={\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m         },\n\u001b[32m     77\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m response = \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[32m     81\u001b[39m     response_metadata = response.trailing_metadata()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/grpc/_interceptor.py:314\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    305\u001b[39m (\n\u001b[32m    306\u001b[39m     new_method,\n\u001b[32m    307\u001b[39m     new_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m    311\u001b[39m     new_compression,\n\u001b[32m    312\u001b[39m ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/grpc/_channel.py:1177\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_call\u001b[39m(\n\u001b[32m   1169\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1170\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1175\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1176\u001b[39m ) -> Tuple[Any, grpc.Call]:\n\u001b[32m-> \u001b[39m\u001b[32m1177\u001b[39m     state, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/grpc/_channel.py:1150\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1133\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1134\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1135\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1148\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1149\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1151\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from RAG_FRAMEWORK import (\n",
    "    PersonDatabase,\n",
    "    prepare_mindmap_chunks,\n",
    "    build_mindmap_index,\n",
    "    query_both_indexes,\n",
    "    make_rag_make_sense,\n",
    ")\n",
    "# Load person JSON from scraper\n",
    "person_db = PersonDatabase()\n",
    "json_folder= \"out_speakers/profiles\"\n",
    "\n",
    "\n",
    "# Iterate over all JSON files in the folder\n",
    "for filename in os.listdir(json_folder):\n",
    "    if filename.endswith(\".json\"):\n",
    "        json_path = os.path.join(json_folder, filename)\n",
    "        print(f\"Processing {json_path}...\")\n",
    "        with open(json_path, \"r\") as f:\n",
    "            scraper_json = json.load(f)\n",
    "        person_db.load_from_scraper_json(scraper_json)\n",
    "\n",
    "\n",
    "# Build FAISS\n",
    "person_db.build_person_chunks()\n",
    "person_db.create_faiss_index()\n",
    "\n",
    "# Load mindmap\n",
    "with open(\"mindmap.json\", \"r\") as f:\n",
    "    mindmap_json = json.load(f)\n",
    "    # print(mindmap_json)\n",
    "mindmap_chunks = prepare_mindmap_chunks(mindmap_json, person_db)\n",
    "print(\"________________\")\n",
    "print(mindmap_chunks)\n",
    "mindmap_index = build_mindmap_index(mindmap_chunks)\n",
    "\n",
    "print(\"\\nEnter your questions about the conversation (type 'exit' to quit):\")\n",
    "history={}\n",
    "\n",
    "while True:\n",
    "    \n",
    "    query = input(\"\\nYour query: \").strip()\n",
    "    if query.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Exiting interactive session.\")\n",
    "        break\n",
    "    \n",
    "    results = query_both_indexes(mindmap_index, mindmap_chunks, person_db, query)\n",
    "    for r in results:\n",
    "        print(f\"{r['source']} | {r.get('person_id')} | {r['text'][:100]}...\")\n",
    "\n",
    "    # RAG answer\n",
    "    answer = make_rag_make_sense(query, results, history)\n",
    "    print(\"\\nüí° Answer:\\n\", answer)\n",
    "\n",
    "    history[query] = answer\n",
    "    \n",
    "    print(\"\\n‚úÖ Chat History:\")\n",
    "    print(\"=\"*20)\n",
    "    for q, a in history.items():\n",
    "        print(f\"Q: {q}\\nA: {a}\\n\")\n",
    "    print(\"=\"*20)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
